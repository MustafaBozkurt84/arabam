{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findspark.init(\"/opt/manual/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Azure/mmlspark   ## LİGHTGBM KULLANIMI\n",
    "#spark = (SparkSession.builder\n",
    "        #.appName(\"HChurn Prediction with LightGBM on Spark\")\n",
    "        #.master(\"yarn\")\n",
    "         #.config(\"spark.memory.fraction\",\"0.7\")\n",
    "         #.config(\"spark.memory.storageFraction\",\"0.3\")\n",
    "         #.config(\"spark.executor.cores\",\"2\") # lightgbm requires at least 2 cores per task      \n",
    "         #.config(\"spark.jars.packages\",\"Azure:mmlspark:0.17\")\n",
    "        #.enableHiveSupport()\n",
    "        #.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmlspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-68176234bd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmlspark'"
     ]
    }
   ],
   "source": [
    "from mmlspark.lightgbm import LightGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".appName(\"arabam_com\") \\\n",
    ".master(\"yarn\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! hdfs dfs -rm /user/train/datasets/arabam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! hdfs dfs -put ~/Desktop/arabam/arabam.csv /user/train/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"csv\") \\\n",
    ".option(\"header\",True) \\\n",
    ".option(\"inferShema\",True) \\\n",
    ".option(\"sep\",\",\")  \\\n",
    ".load(\"hdfs://localhost:9000/user/train/datasets/arabam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>İlan No:</th>\n",
       "      <th>İlan Tarihi:</th>\n",
       "      <th>Marka:</th>\n",
       "      <th>Seri:</th>\n",
       "      <th>Model:</th>\n",
       "      <th>Yıl:</th>\n",
       "      <th>Yakıt Tipi:</th>\n",
       "      <th>Vites Tipi:</th>\n",
       "      <th>Motor Hacmi:</th>\n",
       "      <th>Motor Gücü:</th>\n",
       "      <th>Kilometre:</th>\n",
       "      <th>car_link:</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16265968</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Distinctive</td>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1598 cc</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>82.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>192.500 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16265262</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Progression Plus</td>\n",
       "      <td>2012</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1598 cc</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>165.500 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>125.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16262696</td>\n",
       "      <td>24 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>156</td>\n",
       "      <td>2.0 JTS Distinctive</td>\n",
       "      <td>2003</td>\n",
       "      <td>Benzin</td>\n",
       "      <td>Yarı Otomatik</td>\n",
       "      <td>1801 - 2000 cm3</td>\n",
       "      <td>151 - 175 HP</td>\n",
       "      <td>191.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/galeriden-satilik...</td>\n",
       "      <td>77.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16129020</td>\n",
       "      <td>24 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.4 TB MultiAir Distinctive</td>\n",
       "      <td>2015</td>\n",
       "      <td>LPG &amp; Benzin</td>\n",
       "      <td>Yarı Otomatik</td>\n",
       "      <td>1201 - 1400 cm3</td>\n",
       "      <td>151 - 175 HP</td>\n",
       "      <td>117.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/galeriden-satilik...</td>\n",
       "      <td>194.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16259218</td>\n",
       "      <td>24 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Distinctive</td>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1598 cc</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>66.400 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>180.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>16258876</td>\n",
       "      <td>24 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Distinctive</td>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1598 cc</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>113.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>178.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16257484</td>\n",
       "      <td>23 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>156</td>\n",
       "      <td>1.6 TS</td>\n",
       "      <td>1998</td>\n",
       "      <td>LPG &amp; Benzin</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1598 cc</td>\n",
       "      <td>120 hp</td>\n",
       "      <td>220.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>45.950 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>16255409</td>\n",
       "      <td>23 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>145</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1997</td>\n",
       "      <td>LPG &amp; Benzin</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1596 cc</td>\n",
       "      <td>103 hp</td>\n",
       "      <td>350.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/galeriden-satilik...</td>\n",
       "      <td>36.750 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>16252962</td>\n",
       "      <td>23 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>156</td>\n",
       "      <td>1.6 TS Progression</td>\n",
       "      <td>2004</td>\n",
       "      <td>LPG &amp; Benzin</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1401 - 1600 cm3</td>\n",
       "      <td>101 - 125 HP</td>\n",
       "      <td>175.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>66.000 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15289709</td>\n",
       "      <td>23 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.4 TB Progression Plus</td>\n",
       "      <td>2011</td>\n",
       "      <td>Benzin</td>\n",
       "      <td>Düz</td>\n",
       "      <td>1368 cc</td>\n",
       "      <td>120 hp</td>\n",
       "      <td>247.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>127.000 TL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0      İlan No:        İlan Tarihi:          Marka:          Seri:  \\\n",
       "0   0   16265968      25 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "1   1   16265262      25 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "2   2   16262696      24 Aralık 2020      Alfa Romeo            156      \n",
       "3   3   16129020      24 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "4   4   16259218      24 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "5   5   16258876      24 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "6   6   16257484      23 Aralık 2020      Alfa Romeo            156      \n",
       "7   7   16255409      23 Aralık 2020      Alfa Romeo            145      \n",
       "8   8   16252962      23 Aralık 2020      Alfa Romeo            156      \n",
       "9   9   15289709      23 Aralık 2020      Alfa Romeo      Giulietta      \n",
       "\n",
       "                            Model:      Yıl:       Yakıt Tipi:  \\\n",
       "0           1.6 JTD Distinctive      2014             Dizel      \n",
       "1      1.6 JTD Progression Plus      2012             Dizel      \n",
       "2           2.0 JTS Distinctive      2003            Benzin      \n",
       "3   1.4 TB MultiAir Distinctive      2015      LPG & Benzin      \n",
       "4           1.6 JTD Distinctive      2014             Dizel      \n",
       "5           1.6 JTD Distinctive      2014             Dizel      \n",
       "6                        1.6 TS      1998      LPG & Benzin      \n",
       "7                           1.6      1997      LPG & Benzin      \n",
       "8            1.6 TS Progression      2004      LPG & Benzin      \n",
       "9       1.4 TB Progression Plus      2011            Benzin      \n",
       "\n",
       "         Vites Tipi:         Motor Hacmi:       Motor Gücü:      Kilometre:  \\\n",
       "0             Düz              1598 cc            105 hp       82.000 km      \n",
       "1             Düz              1598 cc            105 hp      165.500 km      \n",
       "2   Yarı Otomatik      1801 - 2000 cm3      151 - 175 HP      191.000 km      \n",
       "3   Yarı Otomatik      1201 - 1400 cm3      151 - 175 HP      117.000 km      \n",
       "4             Düz              1598 cc            105 hp       66.400 km      \n",
       "5             Düz              1598 cc            105 hp      113.000 km      \n",
       "6             Düz              1598 cc            120 hp      220.000 km      \n",
       "7             Düz              1596 cc            103 hp      350.000 km      \n",
       "8             Düz      1401 - 1600 cm3      101 - 125 HP      175.000 km      \n",
       "9             Düz              1368 cc            120 hp      247.000 km      \n",
       "\n",
       "                                           car_link:           price  \n",
       "0  https://www.arabam.com//ilan/sahibinden-satili...    192.500 TL    \n",
       "1  https://www.arabam.com//ilan/sahibinden-satili...    125.000 TL    \n",
       "2  https://www.arabam.com//ilan/galeriden-satilik...     77.000 TL    \n",
       "3  https://www.arabam.com//ilan/galeriden-satilik...    194.000 TL    \n",
       "4  https://www.arabam.com//ilan/sahibinden-satili...    180.000 TL    \n",
       "5  https://www.arabam.com//ilan/sahibinden-satili...    178.000 TL    \n",
       "6  https://www.arabam.com//ilan/sahibinden-satili...     45.950 TL    \n",
       "7  https://www.arabam.com//ilan/galeriden-satilik...     36.750 TL    \n",
       "8  https://www.arabam.com//ilan/sahibinden-satili...     66.000 TL    \n",
       "9  https://www.arabam.com//ilan/sahibinden-satili...    127.000 TL    "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- İlan No:: string (nullable = true)\n",
      " |-- İlan Tarihi:: string (nullable = true)\n",
      " |-- Marka:: string (nullable = true)\n",
      " |-- Seri:: string (nullable = true)\n",
      " |-- Model:: string (nullable = true)\n",
      " |-- Yıl:: string (nullable = true)\n",
      " |-- Yakıt Tipi:: string (nullable = true)\n",
      " |-- Vites Tipi:: string (nullable = true)\n",
      " |-- Motor Hacmi:: string (nullable = true)\n",
      " |-- Motor Gücü:: string (nullable = true)\n",
      " |-- Kilometre:: string (nullable = true)\n",
      " |-- car_link:: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'İlan No:',\n",
       " 'İlan Tarihi:',\n",
       " 'Marka:',\n",
       " 'Seri:',\n",
       " 'Model:',\n",
       " 'Yıl:',\n",
       " 'Yakıt Tipi:',\n",
       " 'Vites Tipi:',\n",
       " 'Motor Hacmi:',\n",
       " 'Motor Gücü:',\n",
       " 'Kilometre:',\n",
       " 'car_link:',\n",
       " 'price']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    df1 = df1.withColumn(col, F.ltrim(F.rtrim(df1[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df1.withColumn(\"motor_hacmi\",F.split('Motor Hacmi:',\"-\")[0]) \\\n",
    ".withColumn(\"price\",F.split(\"price\",\" \")[0]) \\\n",
    ".withColumn(\"kilometre\",F.split(\"Kilometre:\",\" \")[0]) \\\n",
    ".drop(F.col('Motor Hacmi:')) \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.withColumn(\"price\",F.split(\"price\",\".\")[0:2]) \\\n",
    "#.withColumn(\"kilometre\",F.split(\"Kilometre:\",\".\")[0:2]) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =df2.withColumn(\"motor_hacmi\",F.split(\"motor_hacmi\",\" \")[0]) \\\n",
    ".withColumn(\"motor_gucu\",F.split(\"Motor Gücü:\",\" \")[0]) \\\n",
    ".withColumn(\"marka\",F.concat(F.col(\"Marka:\"),F.lit('_'),F.col(\"Seri:\"),F.lit('_'),F.col(\"Model:\"))) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>İlan No:</th>\n",
       "      <th>İlan Tarihi:</th>\n",
       "      <th>Marka:</th>\n",
       "      <th>Seri:</th>\n",
       "      <th>Model:</th>\n",
       "      <th>Yıl:</th>\n",
       "      <th>Yakıt Tipi:</th>\n",
       "      <th>Vites Tipi:</th>\n",
       "      <th>Motor Gücü:</th>\n",
       "      <th>Kilometre:</th>\n",
       "      <th>car_link:</th>\n",
       "      <th>price</th>\n",
       "      <th>motor_hacmi</th>\n",
       "      <th>kilometre</th>\n",
       "      <th>motor_gucu</th>\n",
       "      <th>marka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16265968</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Distinctive</td>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>82.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>192.500</td>\n",
       "      <td>1598</td>\n",
       "      <td>82.000</td>\n",
       "      <td>105</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Distinctive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16265262</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Progression Plus</td>\n",
       "      <td>2012</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>165.500 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>125.000</td>\n",
       "      <td>1598</td>\n",
       "      <td>165.500</td>\n",
       "      <td>105</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Progression Plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0  İlan No:    İlan Tarihi:      Marka:      Seri:  \\\n",
       "0   0  16265968  25 Aralık 2020  Alfa Romeo  Giulietta   \n",
       "1   1  16265262  25 Aralık 2020  Alfa Romeo  Giulietta   \n",
       "\n",
       "                     Model:  Yıl: Yakıt Tipi: Vites Tipi: Motor Gücü:  \\\n",
       "0       1.6 JTD Distinctive  2014       Dizel         Düz      105 hp   \n",
       "1  1.6 JTD Progression Plus  2012       Dizel         Düz      105 hp   \n",
       "\n",
       "   Kilometre:                                          car_link:    price  \\\n",
       "0   82.000 km  https://www.arabam.com//ilan/sahibinden-satili...  192.500   \n",
       "1  165.500 km  https://www.arabam.com//ilan/sahibinden-satili...  125.000   \n",
       "\n",
       "  motor_hacmi kilometre motor_gucu  \\\n",
       "0        1598    82.000        105   \n",
       "1        1598   165.500        105   \n",
       "\n",
       "                                           marka  \n",
       "0       Alfa Romeo_Giulietta_1.6 JTD Distinctive  \n",
       "1  Alfa Romeo_Giulietta_1.6 JTD Progression Plus  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.withColumn(\"price1\",F.split(F.col(\"price\"),\"\\.\").getItem(0)) \\\n",
    ".withColumn(\"price2\",F.split(F.col(\"price\"),\"\\.\").getItem(1)) \\\n",
    ".withColumn(\"price\",F.concat(F.col(\"price1\"),F.col(\"price2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.withColumn(\"km1\",F.split(F.col(\"kilometre\"),\"\\.\").getItem(0)) \\\n",
    ".withColumn(\"km2\",F.split(F.col(\"kilometre\"),\"\\.\").getItem(1)) \\\n",
    ".withColumn(\"km\",F.concat(F.col(\"km1\"),F.col(\"km2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5.drop(F.col(\"km1\")) \\\n",
    ".drop(F.col(\"km2\")) \\\n",
    ".drop(F.col(\"price1\")) \\\n",
    ".drop(F.col(\"price2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>İlan No:</th>\n",
       "      <th>İlan Tarihi:</th>\n",
       "      <th>Marka:</th>\n",
       "      <th>Seri:</th>\n",
       "      <th>Model:</th>\n",
       "      <th>Yıl:</th>\n",
       "      <th>Yakıt Tipi:</th>\n",
       "      <th>Vites Tipi:</th>\n",
       "      <th>Motor Gücü:</th>\n",
       "      <th>Kilometre:</th>\n",
       "      <th>car_link:</th>\n",
       "      <th>price</th>\n",
       "      <th>motor_hacmi</th>\n",
       "      <th>kilometre</th>\n",
       "      <th>motor_gucu</th>\n",
       "      <th>marka</th>\n",
       "      <th>km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16265968</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Distinctive</td>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>82.000 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>192500</td>\n",
       "      <td>1598</td>\n",
       "      <td>82.000</td>\n",
       "      <td>105</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Distinctive</td>\n",
       "      <td>82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16265262</td>\n",
       "      <td>25 Aralık 2020</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Giulietta</td>\n",
       "      <td>1.6 JTD Progression Plus</td>\n",
       "      <td>2012</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>105 hp</td>\n",
       "      <td>165.500 km</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>125000</td>\n",
       "      <td>1598</td>\n",
       "      <td>165.500</td>\n",
       "      <td>105</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Progression Plus</td>\n",
       "      <td>165500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0  İlan No:    İlan Tarihi:      Marka:      Seri:  \\\n",
       "0   0  16265968  25 Aralık 2020  Alfa Romeo  Giulietta   \n",
       "1   1  16265262  25 Aralık 2020  Alfa Romeo  Giulietta   \n",
       "\n",
       "                     Model:  Yıl: Yakıt Tipi: Vites Tipi: Motor Gücü:  \\\n",
       "0       1.6 JTD Distinctive  2014       Dizel         Düz      105 hp   \n",
       "1  1.6 JTD Progression Plus  2012       Dizel         Düz      105 hp   \n",
       "\n",
       "   Kilometre:                                          car_link:   price  \\\n",
       "0   82.000 km  https://www.arabam.com//ilan/sahibinden-satili...  192500   \n",
       "1  165.500 km  https://www.arabam.com//ilan/sahibinden-satili...  125000   \n",
       "\n",
       "  motor_hacmi kilometre motor_gucu  \\\n",
       "0        1598    82.000        105   \n",
       "1        1598   165.500        105   \n",
       "\n",
       "                                           marka      km  \n",
       "0       Alfa Romeo_Giulietta_1.6 JTD Distinctive   82000  \n",
       "1  Alfa Romeo_Giulietta_1.6 JTD Progression Plus  165500  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- İlan No:: string (nullable = true)\n",
      " |-- İlan Tarihi:: string (nullable = true)\n",
      " |-- Marka:: string (nullable = true)\n",
      " |-- Seri:: string (nullable = true)\n",
      " |-- Model:: string (nullable = true)\n",
      " |-- Yıl:: string (nullable = true)\n",
      " |-- Yakıt Tipi:: string (nullable = true)\n",
      " |-- Vites Tipi:: string (nullable = true)\n",
      " |-- Motor Gücü:: string (nullable = true)\n",
      " |-- Kilometre:: string (nullable = true)\n",
      " |-- car_link:: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- motor_hacmi: string (nullable = true)\n",
      " |-- kilometre: string (nullable = true)\n",
      " |-- motor_gucu: string (nullable = true)\n",
      " |-- marka: string (nullable = true)\n",
      " |-- km: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df6.select(\n",
    "F.col('Yıl:').cast(\"int\"),\n",
    "F.col('Yakıt Tipi:'),\n",
    "F.col('Vites Tipi:'),\n",
    "F.col('km').cast(\"int\"),\n",
    "F.col(\"price\").cast(\"int\"),\n",
    "F.col(\"car_link:\"),\n",
    "F.col(\"marka\"),\n",
    "F.col(\"Seri:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Yıl:: integer (nullable = true)\n",
      " |-- Yakıt Tipi:: string (nullable = true)\n",
      " |-- Vites Tipi:: string (nullable = true)\n",
      " |-- km: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- car_link:: string (nullable = true)\n",
      " |-- marka: string (nullable = true)\n",
      " |-- Seri:: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yıl:</th>\n",
       "      <th>Yakıt Tipi:</th>\n",
       "      <th>Vites Tipi:</th>\n",
       "      <th>km</th>\n",
       "      <th>price</th>\n",
       "      <th>car_link:</th>\n",
       "      <th>marka</th>\n",
       "      <th>Seri:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>82000</td>\n",
       "      <td>192500</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Distinctive</td>\n",
       "      <td>Giulietta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>Dizel</td>\n",
       "      <td>Düz</td>\n",
       "      <td>165500</td>\n",
       "      <td>125000</td>\n",
       "      <td>https://www.arabam.com//ilan/sahibinden-satili...</td>\n",
       "      <td>Alfa Romeo_Giulietta_1.6 JTD Progression Plus</td>\n",
       "      <td>Giulietta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>Benzin</td>\n",
       "      <td>Yarı Otomatik</td>\n",
       "      <td>191000</td>\n",
       "      <td>77000</td>\n",
       "      <td>https://www.arabam.com//ilan/galeriden-satilik...</td>\n",
       "      <td>Alfa Romeo_156_2.0 JTS Distinctive</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Yıl: Yakıt Tipi:    Vites Tipi:      km   price  \\\n",
       "0  2014       Dizel            Düz   82000  192500   \n",
       "1  2012       Dizel            Düz  165500  125000   \n",
       "2  2003      Benzin  Yarı Otomatik  191000   77000   \n",
       "\n",
       "                                           car_link:  \\\n",
       "0  https://www.arabam.com//ilan/sahibinden-satili...   \n",
       "1  https://www.arabam.com//ilan/sahibinden-satili...   \n",
       "2  https://www.arabam.com//ilan/galeriden-satilik...   \n",
       "\n",
       "                                           marka      Seri:  \n",
       "0       Alfa Romeo_Giulietta_1.6 JTD Distinctive  Giulietta  \n",
       "1  Alfa Romeo_Giulietta_1.6 JTD Progression Plus  Giulietta  \n",
       "2             Alfa Romeo_156_2.0 JTS Distinctive        156  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "km int type has 568 null values\n"
     ]
    }
   ],
   "source": [
    "# Null check\n",
    "for(col_name, col_type) in zip(df7.columns, df7.dtypes):\n",
    "    null_count = df7.filter( (F.col(col_name).isNull()) | (F.col(col_name) == \"\")).count()\n",
    "    if(  null_count > 0 ):\n",
    "        print(\"{} {} type has {} null values\".format(col_name, col_type[1], null_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=df7.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categoric_cols = []\n",
    "numeric_cols = []\n",
    "discarted_cols = []\n",
    "label_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column seperation\n",
    "for col_name in df8.dtypes:\n",
    "    if (col_name[0] not in []):\n",
    "        if (col_name[1] == 'string'):\n",
    "            categoric_cols.append(col_name[0])\n",
    "        else: numeric_cols.append(col_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "| Yakıt Tipi:|TotalCount|\n",
      "+------------+----------+\n",
      "|       Dizel|      9585|\n",
      "|LPG & Benzin|      7079|\n",
      "|      Benzin|      5202|\n",
      "|      Hibrit|         7|\n",
      "|    Elektrik|         3|\n",
      "+------------+----------+\n",
      "\n",
      "+-------------+----------+\n",
      "|  Vites Tipi:|TotalCount|\n",
      "+-------------+----------+\n",
      "|          Düz|     12836|\n",
      "|Yarı Otomatik|      4722|\n",
      "|     Otomatik|      4318|\n",
      "+-------------+----------+\n",
      "\n",
      "+--------------------+----------+\n",
      "|           car_link:|TotalCount|\n",
      "+--------------------+----------+\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "|https://www.araba...|         1|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+----------+\n",
      "|               marka|TotalCount|\n",
      "+--------------------+----------+\n",
      "|Dacia_Sandero_1.5...|       365|\n",
      "|Honda_Civic_1.6 i...|       215|\n",
      "|Chevrolet_Cruze_1...|       197|\n",
      "|     Tofaş_Doğan_SLX|       167|\n",
      "|Peugeot_301_1.6 H...|       158|\n",
      "|Honda_Civic_1.6 i...|       125|\n",
      "|Nissan_Micra_1.2 ...|       125|\n",
      "|Seat_Leon_1.6 TDI...|       122|\n",
      "|Audi_A4_A4 Sedan ...|       119|\n",
      "|     Lada_Samara_1.5|       115|\n",
      "|Volvo_S60_1.6 D P...|       110|\n",
      "|Citroen_C-Elysee_...|       104|\n",
      "|Ford_Focus_1.6 TD...|       103|\n",
      "|       Lada_Vega_1.5|       102|\n",
      "|       Tofaş_Şahin_S|        97|\n",
      "|Tofaş_Şahin_Şahin...|        92|\n",
      "|Audi_A6_A6 Sedan ...|        88|\n",
      "|Dacia_Lodgy_1.5 d...|        88|\n",
      "|Dacia_Logan_1.5 d...|        84|\n",
      "|Fiat_Egea_1.3 Mul...|        83|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------+\n",
      "|   Seri:|TotalCount|\n",
      "+--------+----------+\n",
      "|   Civic|       806|\n",
      "| Corolla|       671|\n",
      "| Sandero|       594|\n",
      "|   Focus|       538|\n",
      "|    Leon|       530|\n",
      "|   Astra|       516|\n",
      "|   Cruze|       468|\n",
      "|3 Serisi|       449|\n",
      "|      A3|       436|\n",
      "|   Micra|       417|\n",
      "|C-Elysee|       401|\n",
      "|     Rio|       377|\n",
      "|       C|       372|\n",
      "| Octavia|       370|\n",
      "|   Doğan|       351|\n",
      "|   Şahin|       320|\n",
      "|     S60|       318|\n",
      "|  Passat|       305|\n",
      "|5 Serisi|       304|\n",
      "|  Fiesta|       290|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col_name in categoric_cols:\n",
    "    df8.groupBy(col_name).agg(F.count(\"*\").alias(\"TotalCount\")).orderBy(F.desc(\"TotalCount\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yıl:',\n",
       " 'Yakıt Tipi:',\n",
       " 'Vites Tipi:',\n",
       " 'km',\n",
       " 'price',\n",
       " 'car_link:',\n",
       " 'marka',\n",
       " 'Seri:']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# column seperation after analysis\n",
    "categoric_cols = []\n",
    "numeric_cols = []\n",
    "# Why we discard these? Because they have high cardinality. In other words they have too many distinct categories\n",
    "# Adding them to model will not do good if not too bad.\n",
    "discarted_cols = ['car_link:']\n",
    "label_col = ['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col_name in df8.dtypes:\n",
    "    if (col_name[0] not in discarted_cols+label_col):\n",
    "        if (col_name[1] == 'string'):\n",
    "            categoric_cols.append(col_name[0])\n",
    "        else: numeric_cols.append(col_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yakıt Tipi: has 5 distinct category.\n",
      "Vites Tipi: has 3 distinct category.\n",
      "marka has 2998 distinct category.\n",
      "Seri: has 403 distinct category.\n"
     ]
    }
   ],
   "source": [
    "# Here we count the distinct categories in categoric columns. If there is more than two,\n",
    "# we will add those to to_be_onehotencoded_cols list If there is just 2 we don't need to use onehotencoder\n",
    "# So if distinct category gt 2 we have to add it to_be_onehotencoded_cols list\n",
    "to_be_onehotencoded_cols = []\n",
    "\n",
    "for col_name in categoric_cols:\n",
    "    count = df8.select(col_name).distinct().count()\n",
    "    if count > 2:\n",
    "        to_be_onehotencoded_cols.append(col_name)\n",
    "    print(\"{} has {} distinct category.\".format(col_name, count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yakıt Tipi:', 'Vites Tipi:', 'marka', 'Seri:']\n"
     ]
    }
   ],
   "source": [
    "print(to_be_onehotencoded_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will hold stringIndexer objects and column names\n",
    "my_dict = {}\n",
    "\n",
    "# Will collect StringIndexer ojects\n",
    "string_indexer_objs = []\n",
    "\n",
    "# Will collect StringIndexer output colnames\n",
    "string_indexer_output_names = []\n",
    "\n",
    "# Will collect OneHotEncoder output colnames\n",
    "ohe_col_input_names = []\n",
    "ohe_col_output_names = []\n",
    "\n",
    "for col_name in categoric_cols:\n",
    "    my_dict[col_name+\"_indexobj\"] = StringIndexer() \\\n",
    "    .setHandleInvalid('skip') \\\n",
    "    .setInputCol(col_name) \\\n",
    "    .setOutputCol(col_name+\"_indexed\")\n",
    "    \n",
    "    string_indexer_objs.append(my_dict.get(col_name+\"_indexobj\"))\n",
    "    string_indexer_output_names.append(col_name+\"_indexed\")\n",
    "    if col_name in to_be_onehotencoded_cols:\n",
    "        ohe_col_input_names.append(col_name+\"_indexed\")\n",
    "        ohe_col_output_names.append(col_name+\"_ohe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexer_2e6e36f5809a, StringIndexer_b5ae843d899e, StringIndexer_1c1dd820d6f4, StringIndexer_48d04322b490]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(string_indexer_objs)\n",
    "print(len(string_indexer_objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yakıt Tipi:_indexed', 'Vites Tipi:_indexed', 'marka_indexed', 'Seri:_indexed']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(ohe_col_input_names)\n",
    "print(len(ohe_col_input_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yakıt Tipi:_indexed', 'Vites Tipi:_indexed', 'marka_indexed', 'Seri:_indexed']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(string_indexer_output_names)\n",
    "print(len(string_indexer_output_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnehotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder() \\\n",
    ".setInputCols(ohe_col_input_names) \\\n",
    ".setOutputCols(ohe_col_output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_indexer_col_names_ohe_exluded = list(set(string_indexer_output_names).difference(set(ohe_col_input_names)))\n",
    "string_indexer_col_names_ohe_exluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns verified\n"
     ]
    }
   ],
   "source": [
    "if len(categoric_cols) == (len(string_indexer_col_names_ohe_exluded)+len(ohe_col_output_names)):\n",
    "    print(\"Columns verified\")\n",
    "else: print(\"Columns are not verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setHandleInvalid(\"skip\") \\\n",
    ".setInputCols(numeric_cols+string_indexer_col_names_ohe_exluded+ohe_col_output_names) \\\n",
    ".setOutputCol('unscaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().setInputCol(\"unscaled_features\").setOutputCol(\"scaled_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA().setInputCol(\"scaled_features\").setK(10).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_linear = LinearRegression() \\\n",
    ".setFeaturesCol(\"scaled_features\") \\\n",
    ".setLabelCol(\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator: GBTRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_GBT=GBTRegressor() \\\n",
    ".setFeaturesCol(\"scaled_features\") \\\n",
    ".setLabelCol(\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator: LightgbmRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmlspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-68176234bd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmlspark'"
     ]
    }
   ],
   "source": [
    "\n",
    "from mmlspark.lightgbm import LightGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGBMRegressor(objective='quantile',\n",
    "                          alpha=0.2,\n",
    "                          learningRate=0.3,\n",
    "                          numLeaves=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Estimator: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_RandomForest = RandomForestRegressor() \\\n",
    ".setFeaturesCol(\"scaled_features\") \\\n",
    ".setLabelCol(\"price\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list=[estimator_RandomForest,estimator_GBT,estimator_linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_obj = Pipeline().setStages(string_indexer_objs+[encoder, assembler, scaler, estimator_RandomForest])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df8.randomSplit([0.80,0.10], seed=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19430, 2446)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(),test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MoDEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline_obj.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.stages[-1].write().overwrite().save(\"~/Desktop/arabam/randomForestmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|price|prediction        |\n",
      "+-----+------------------+\n",
      "|45000|75524.91369594776 |\n",
      "|45000|104867.20418653838|\n",
      "|66000|79713.24130845729 |\n",
      "|10500|54989.06803951076 |\n",
      "|30000|95470.89045144807 |\n",
      "|65000|182017.09319988932|\n",
      "|20000|54989.06803951076 |\n",
      "|28500|42925.14117179888 |\n",
      "|18000|42925.14117179888 |\n",
      "|21950|42925.14117179888 |\n",
      "|20500|54989.06803951076 |\n",
      "|40500|98742.95275730538 |\n",
      "|66700|104867.20418653838|\n",
      "|34750|97494.90154985644 |\n",
      "|29500|52258.31272601751 |\n",
      "|24000|53475.68723910172 |\n",
      "|38000|53475.68723910172 |\n",
      "|20100|44142.51568488308 |\n",
      "|46000|54989.06803951076 |\n",
      "|56250|58046.303429914595|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.select('price','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3204.evaluate.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:238)\njava.lang.Thread.run(Thread.java:748)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:238)\njava.lang.Thread.run(Thread.java:748)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:111)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1471)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:398)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:389)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:295)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:3198)\n\tat org.apache.spark.sql.Dataset.rdd(Dataset.scala:3196)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:106)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-fbf6e6cfe791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/manual/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/manual/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/manual/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/manual/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/manual/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3204.evaluate.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:238)\njava.lang.Thread.run(Thread.java:748)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:238)\njava.lang.Thread.run(Thread.java:748)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:111)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1471)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:398)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:389)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:295)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:133)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:3198)\n\tat org.apache.spark.sql.Dataset.rdd(Dataset.scala:3196)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:106)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "evaluator.evaluate(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rmse'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : model_RandomForestRegressor_5e6169ef1c88 metrik rmse : 66878.08015322544 \n",
      "model name : model_GBTRegressor_dee3d25ee70c metrik rmse : 52907.760533007095 \n",
      "model name : model_LinearRegression_d4859fc83a1a metrik rmse : 46810.365265321285 \n"
     ]
    }
   ],
   "source": [
    "model_list=[estimator_RandomForest,estimator_GBT,estimator_linear]\n",
    "for model_obj in model_list:\n",
    "    model=Pipeline().setStages(string_indexer_objs+[encoder, assembler, scaler, model_obj]).fit(train_df)\n",
    "    transformed_df = model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(labelCol='price')\n",
    "    evaluator.evaluate(transformed_df)\n",
    "    evaluator.getMetricName()\n",
    "    print(\"model name : {} metrik {} : {} \".format(\"model_\"+str(model_obj),evaluator.getMetricName(),evaluator.evaluate(transformed_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19430, 2446)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(),test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidatorModel, ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    ".addGrid(estimator_linear.regParam, [0.01,0.1,1.0,10.0]) \\\n",
    ".addGrid(estimator_linear.elasticNetParam,[0.0,0.5,1.0]) \\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_obj = Pipeline().setStages(string_indexer_objs+[encoder, assembler, scaler, estimator_linear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline_obj,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol='price'),\n",
    "                          numFolds=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-2826757e8700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/manual/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/manual/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cvModel = crossval.fit(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(bestModel.transform(df8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate(cvModel.transform(df8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.write().overwrite().save(\"~/Desktop/arabam/arabam_best_model_linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
